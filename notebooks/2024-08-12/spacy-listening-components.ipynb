{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b843d3b",
   "metadata": {},
   "source": [
    "I've been working with [`spacy`](https://spacy.io/) more and more over the years, and I thought it'd be a good idea to write about pieces of the configuration system. There are mentions of it throughout the [docs](https://spacy.io/usage/training#config) and in some of the `spacy` 3.0 [videos](https://youtu.be/BWhh3r6W-qE), but I have yet to find a super detailed breakdown of what's going on—the closest being this [blog](https://explosion.ai/blog/spacy-v3-project-config-systems#spacy-config-system). This post will hopefully shed some light on the components that [*share* or *listen to*](https://spacy.io/usage/embeddings-transformers#embedding-layers) previous components in the pipeline.\n",
    "\n",
    "Let's start with a brief demo of `spacy`.\n",
    "\n",
    "> Install `spacy` and the `en_core_web_sm` model if you want to follow along:\n",
    "> ```shell\n",
    "$ pip install spacy\n",
    "$ python -m spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ccc383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, my name is Ian and this is my blog.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Hi, my name is Ian and this is my blog.\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca89d6a2",
   "metadata": {},
   "source": [
    "Nothing fancy on the surface, but this [`doc`](https://spacy.io/api/doc) object that we've created is the product of sending our string of characters through a [pipeline of models](https://spacy.io/usage/processing-pipelines), or as `spacy` likes to call them, [components](https://spacy.io/usage/processing-pipelines#pipelines). We can view the pipeline components via the [`nlp.pipeline` property](https://spacy.io/api/language#attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474cc814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x25ec707bf50>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x25ec7224290>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x25ec6f81540>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x25ec70c8b90>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x25ec6f05050>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x25ec6f81230>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dad0f9",
   "metadata": {},
   "source": [
    "And we can get more component information with [`nlp.analyze_pipes`](https://spacy.io/api/language#analyze_pipes) such as what each assigns, their requirements, their scoring metrics, whether they retokenize, and in what order the components perform their annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b893645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================= Pipeline Overview =============================\u001b[0m\n",
      "\n",
      "#   Component         Assigns               Requires   Scores             Retokenizes\n",
      "-   ---------------   -------------------   --------   ----------------   -----------\n",
      "0   tok2vec           doc.tensor                                          False      \n",
      "                                                                                     \n",
      "1   tagger            token.tag                        tag_acc            False      \n",
      "                                                                                     \n",
      "2   parser            token.dep                        dep_uas            False      \n",
      "                      token.head                       dep_las                       \n",
      "                      token.is_sent_start              dep_las_per_type              \n",
      "                      doc.sents                        sents_p                       \n",
      "                                                       sents_r                       \n",
      "                                                       sents_f                       \n",
      "                                                                                     \n",
      "3   attribute_ruler                                                       False      \n",
      "                                                                                     \n",
      "4   lemmatizer        token.lemma                      lemma_acc          False      \n",
      "                                                                                     \n",
      "5   ner               doc.ents                         ents_f             False      \n",
      "                      token.ent_iob                    ents_p                        \n",
      "                      token.ent_type                   ents_r                        \n",
      "                                                       ents_per_type                 \n",
      "\n",
      "\u001b[38;5;2m✔ No problems found.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# note the semicolon (;) to reduce output after the table.\n",
    "nlp.analyze_pipes(pretty=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a487051",
   "metadata": {},
   "source": [
    "Notice the first component, `tok2vec`. This [component](https://spacy.io/api/tok2vec) is responsible for mapping tokens to vectors, i.e., creating an [embedding layer](https://spacy.io/usage/embeddings-transformers), and making them available for later components to use via the `doc.tensor` attribute.\n",
    "> Note, this is not the same as a [`tokenizer`](https://spacy.io/api/tokenizer).\n",
    "\n",
    "In the [`en_core_web_sm`](https://spacy.io/models/en#en_core_web_sm) pipeline, we can see that the [`tagger`](https://spacy.io/api/tagger) and [`parser`](https://spacy.io/api/dependencyparser) components both use the `tok2vec`'s output by viewing the `tok2vec.listening_components`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "861a632b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok2vec = nlp.get_pipe(\"tok2vec\")\n",
    "tok2vec.listening_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff13e4e3",
   "metadata": {},
   "source": [
    "On the flip side, we can see which components *use* a `tok2vec` model by checking their configurations via `nlp.get_pipe_config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9710ff6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    name for name in nlp.pipe_names\n",
    "    if (model := nlp.get_pipe_config(name).get(\"model\")) is not None\n",
    "    and model.get(\"tok2vec\") is not None\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a2c823",
   "metadata": {},
   "source": [
    "The `tagger` and `parser` are both present as expected, but so is the `ner` component which has its own `tok2vec` layer, separate from the `tok2vec` at the beginning of the `nlp.pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "821c04fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2Vec.v2',\n",
       " 'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "  'width': 96,\n",
       "  'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE'],\n",
       "  'rows': [5000, 1000, 2500, 2500],\n",
       "  'include_static_vectors': False},\n",
       " 'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "  'width': 96,\n",
       "  'depth': 4,\n",
       "  'window_size': 1,\n",
       "  'maxout_pieces': 3}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tok2vec = nlp.get_pipe_config(\"ner\")[\"model\"][\"tok2vec\"]\n",
    "ner_tok2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950e589e",
   "metadata": {},
   "source": [
    "This is an example of an *independent* component—it can stand alone without a `tok2vec` component being present in the pipeline.\n",
    "\n",
    "The `tagger` and `parser` components both *listen to* or *share* the `tok2vec` component's output in the `nlp.pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d56d3a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2VecListener.v1',\n",
       " 'width': '${components.tok2vec.model.encode:width}',\n",
       " 'upstream': 'tok2vec'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_tok2vec = nlp.get_pipe_config(\"tagger\")[\"model\"][\"tok2vec\"]\n",
    "tagger_tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ba93487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2VecListener.v1',\n",
       " 'width': '${components.tok2vec.model.encode:width}',\n",
       " 'upstream': 'tok2vec'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser_tok2vec = nlp.get_pipe_config(\"parser\")[\"model\"][\"tok2vec\"]\n",
    "parser_tok2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf88965",
   "metadata": {},
   "source": [
    "Listening to/sharing an upstream component has some pros and cons including speed and flexibility (see my [stack overflow answer](https://stackoverflow.com/a/76774652/6509519) for an experiment). Sometimes sharing a component can help boost later components metrics, and other times it's easier to have something more independent.\n",
    "\n",
    "*Most* trainable components require a `tok2vec` layer, so when it comes to adding components to a pipeline, we have options.\n",
    "- We could add a component with its own `tok2vec` similar to the `ner` component.\n",
    "- We could add a component and have it listen to the existing `tok2vec` layer.\n",
    "- We could add both a component and have it listen to a *new* `tok2vec` component, separate from the existing one (uncommon).\n",
    "\n",
    "Here is an example of the first option: we'll add a [`senter`](https://spacy.io/api/sentencerecognizer) component—not to be confused with the disbaled `senter` component that comes pretrained—and view its `tok2vec` setup.\n",
    "\n",
    "> Note, you could do this with a custom component as well assuming it's registered/in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d3f403b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.HashEmbedCNN.v2',\n",
       " 'pretrained_vectors': None,\n",
       " 'width': 12,\n",
       " 'depth': 1,\n",
       " 'embed_size': 2000,\n",
       " 'window_size': 1,\n",
       " 'maxout_pieces': 2,\n",
       " 'subword_features': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable, then removing existing ``senter`` model (disabled by default).\n",
    "nlp.enable_pipe(\"senter\")\n",
    "nlp.remove_pipe(\"senter\")\n",
    "\n",
    "# Adding new ``senter`` model.\n",
    "nlp.add_pipe(\"senter\", after=\"parser\")\n",
    "\n",
    "# View ``senter`` tok2vec config.\n",
    "senter_tok2vec = nlp.get_pipe_config(\"senter\")[\"model\"][\"tok2vec\"]\n",
    "senter_tok2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a65ebc",
   "metadata": {},
   "source": [
    "Pretty easy to do as the the `senter` component factory comes with its own `tok2vec` layer. If we wanted something more like the second option, we'd need to include a [`config`](https://spacy.io/api/language#config) telling `spacy` that we want the `senter` to listen to the existing `tok2vec` component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa3c1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from confection import Config  # For interpolating the ``nlp.config``.\n",
    "\n",
    "# Extracting width from ``tagger``'s interpolated config beacuse it listens to ``tok2vec``.\n",
    "inter_config = Config(nlp.config).interpolate()\n",
    "width = inter_config[\"components\"][\"tagger\"][\"model\"][\"tok2vec\"][\"width\"]\n",
    "\n",
    "senter_config = {\n",
    "    \"model\": {\n",
    "        \"tok2vec\": {\n",
    "            \"@architectures\": \"spacy.Tok2VecListener.v1\",\n",
    "            \"width\": width,\n",
    "            \"upstream\": \"tok2vec\",\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "# Before adding ``senter`` with listener.\n",
    "tok2vec.listening_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eace233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'senter']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing existing ``senter`` model without listener.\n",
    "nlp.remove_pipe(\"senter\")\n",
    "\n",
    "# Adding new ``senter`` model with listener.\n",
    "nlp.add_pipe(\"senter\", after=\"parser\", config=senter_config)\n",
    "\n",
    "# After adding ``senter`` with listener.\n",
    "tok2vec.listening_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5532e1",
   "metadata": {},
   "source": [
    "What's with the nested dictionaries? Why not use a method or more object-oriented approach? These are questions I asked myself when the config system was first introduced. Since then I've grown used to it not because it's easier, but because it's more maintainable (especially when you use it the way it was designed to be used, i.e., not in a notebook).\n",
    "\n",
    "Because I consider the third option uncommon, I'm not going to show it. But if you wanted to try it for yourself you'd follow these steps:\n",
    "1. Add a secondary `tok2vec` layer with a different name (something like `tok2vec.secondary`)\n",
    "2. Add a component via the `nlp.add_pipe` method and modify the config to point at `tok2vec.secondary` instead of `tok2vec` in the `upstream` field.\n",
    "\n",
    "If you want to look into what's going on under the hood, I've tracked down the [`nlp.add_pipe` source code](https://github.com/explosion/spaCy/blob/8cda27aefaea64e899061564cdedd85f0fa269e5/spacy/language.py#L764) as well as [additional documentation specific to the \"listener\" components](https://github.com/explosion/spaCy/blob/master/extra/DEVELOPER_DOCS/Listeners.md). Please have a gander and drop a comment if you'd like to discuss further.\n",
    "\n",
    "We've walked through adding independent and listener components; how do we take an existing listener component and make it independent? Rolling with the notebook approach first, we would use the [`nlp.replace_listeners`](https://spacy.io/api/language#replace_listeners) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e03d6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2VecListener.v1',\n",
       " 'width': 96,\n",
       " 'upstream': 'tok2vec'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before making the listening ``senter`` component independent.\n",
    "nlp.get_pipe_config(\"senter\")[\"model\"][\"tok2vec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2b6b054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2Vec.v2',\n",
       " 'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "  'width': '${components.tok2vec.model.encode:width}',\n",
       "  'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY', 'IS_SPACE'],\n",
       "  'rows': [5000, 1000, 2500, 2500, 50, 50],\n",
       "  'include_static_vectors': False},\n",
       " 'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "  'width': 96,\n",
       "  'depth': 4,\n",
       "  'window_size': 1,\n",
       "  'maxout_pieces': 3}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.replace_listeners(\n",
    "    tok2vec_name=\"tok2vec\",\n",
    "    pipe_name=\"senter\",\n",
    "    # Each ``listener`` is represented with TOML-like structure.\n",
    "    listeners=[\"model.tok2vec\"]\n",
    ")\n",
    "\n",
    "# After making the listening ``senter`` component independent.\n",
    "nlp.get_pipe_config(\"senter\")[\"model\"][\"tok2vec\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c566e2",
   "metadata": {},
   "source": [
    "Almost as easy as adding an independent component to the pipeline!\n",
    "\n",
    "Now normally you'd only make a component independent if you were going to freeze it. For example, if you wanted the `en_core_web_sm`'s `tagger` component to annotate some text in a new pipeline, but didn't want to change its underlying weights. Because of all the settings that need to be handled, I recommend doing this via the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98302395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.pipeline.tok2vec import DEFAULT_TOK2VEC_MODEL\n",
    "\n",
    "# Create a new pipeline with an independent ``tagger`` from the ``en_core_web_sm`` model,\n",
    "# and a new ``parser`` that will listen to the pipeline's ``tok2vec`` layer.\n",
    "new_config = {\n",
    "    \"nlp\": {\n",
    "        \"pipeline\": [\"tok2vec\", \"tagger\", \"parser\"]\n",
    "    },\n",
    "    \"components\": {\n",
    "        \"tok2vec\": {\n",
    "            \"factory\": \"tok2vec\",\n",
    "            \"model\": DEFAULT_TOK2VEC_MODEL,\n",
    "        },\n",
    "        \"tagger\": {\n",
    "            \"source\": \"en_core_web_sm\",\n",
    "            \"replace_listeners\": [\"model.tok2vec\"],\n",
    "        },\n",
    "        \"parser\": {\n",
    "            \"factory\": \"parser\",\n",
    "            \"model\": {\n",
    "                \"tok2vec\": {\n",
    "                    \"@architectures\": \"spacy.Tok2VecListener.v1\",\n",
    "                    \"width\": \"${components.tok2vec.model:width}\",\n",
    "                    \"upstream\": \"tok2vec\",\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"frozen_components\": [\"tagger\"],\n",
    "        \"annotating_components\": [\"tagger\"]\n",
    "    },\n",
    "}\n",
    "new_nlp = spacy.blank(\"en\", config=new_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fb4bd9",
   "metadata": {},
   "source": [
    "And there you have it. A more detailed explanation of how to add an independent component, add a listening component, and make an existing listening component independent. Please leave a comment if you have any questions or would like me to drill deeper into another part of the `spacy` config system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
