{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b843d3b",
   "metadata": {},
   "source": [
    "I've been working with [`spacy`](https://spacy.io/) more and more over the years, and I thought it'd be a good idea to write about pieces of the configuration system. There are mentions of it throughout the [docs](https://spacy.io/usage/training#config) and in some of the `spacy` 3.0 [videos](https://youtu.be/BWhh3r6W-qE), but I have yet to find a super detailed breakdown of what's going on (except maybe in this [blog](https://explosion.ai/blog/spacy-v3-project-config-systems#spacy-config-system)). This post will hopefully shed some light on the components that *share* or *listen to* previous components in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca01a23",
   "metadata": {},
   "source": [
    "Let's start with a brief demo of `spacy`.\n",
    "\n",
    "> Install `spacy` and the `en_core_web_sm` model if you want to follow along:\n",
    "> ```shell\n",
    "$ pip install spacy\n",
    "$ python -m spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b4d10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, my name is Ian and this is my blog.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Hi, my name is Ian and this is my blog.\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae2f20",
   "metadata": {},
   "source": [
    "Nothing fancy on the surface, but this [`doc`](https://spacy.io/api/doc) object that we've created is the product of sending our string of characters through a [pipeline of models](https://spacy.io/usage/processing-pipelines), or as `spacy` likes to call them, [components](https://spacy.io/usage/processing-pipelines#pipelines). We can view the pipeline components via the [`nlp.pipeline` property](https://spacy.io/api/language#attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16e92e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x21c3db2bbf0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x21c3dcd4350>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x21c3da31700>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x21c3db76e50>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x21c3d9b5490>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x21c3da313f0>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ab9ec",
   "metadata": {},
   "source": [
    "And we can get more component information with [`nlp.analyze_pipes`](https://spacy.io/api/language#analyze_pipes) such as what each assigns, their requirements, their scoring metrics, whether they retokenize, and in what order the components perform their annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec91ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================= Pipeline Overview =============================\u001b[0m\n",
      "\n",
      "#   Component         Assigns               Requires   Scores             Retokenizes\n",
      "-   ---------------   -------------------   --------   ----------------   -----------\n",
      "0   tok2vec           doc.tensor                                          False      \n",
      "                                                                                     \n",
      "1   tagger            token.tag                        tag_acc            False      \n",
      "                                                                                     \n",
      "2   parser            token.dep                        dep_uas            False      \n",
      "                      token.head                       dep_las                       \n",
      "                      token.is_sent_start              dep_las_per_type              \n",
      "                      doc.sents                        sents_p                       \n",
      "                                                       sents_r                       \n",
      "                                                       sents_f                       \n",
      "                                                                                     \n",
      "3   attribute_ruler                                                       False      \n",
      "                                                                                     \n",
      "4   lemmatizer        token.lemma                      lemma_acc          False      \n",
      "                                                                                     \n",
      "5   ner               doc.ents                         ents_f             False      \n",
      "                      token.ent_iob                    ents_p                        \n",
      "                      token.ent_type                   ents_r                        \n",
      "                                                       ents_per_type                 \n",
      "\n",
      "\u001b[38;5;2mâœ” No problems found.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# note the semicolon (;) to reduce output after the table.\n",
    "nlp.analyze_pipes(pretty=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203d1a84",
   "metadata": {},
   "source": [
    "Notice the first component, `tok2vec`. This [component](https://spacy.io/api/tok2vec) is responsible for mapping tokens to vectors, i.e., creating an [embedding layer](https://spacy.io/usage/embeddings-transformers), and making them available for later components to use via the `doc.tensor` attribute.\n",
    "> Note, this is not the same as a [`tokenizer`](https://spacy.io/api/tokenizer).\n",
    "\n",
    "In the [`en_core_web_sm`](https://spacy.io/models/en#en_core_web_sm) pipeline, we can see that the [`tagger`](https://spacy.io/api/tagger) and [`parser`](https://spacy.io/api/dependencyparser) components both use the `tok2vec`'s output by accessing the `tok2vec.listening_components`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c62e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok2vec = nlp.get_pipe(\"tok2vec\")\n",
    "tok2vec.listening_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e4df39",
   "metadata": {},
   "source": [
    "On the flip side, we can see which components *use* a `tok2vec` model by checking their configuration via `nlp.get_pipe_config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c6f570a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    name\n",
    "    for name in nlp.pipe_names\n",
    "    if (model := nlp.get_pipe_config(name).get(\"model\")) is not None\n",
    "    and model.get(\"tok2vec\") is not None\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a1741",
   "metadata": {},
   "source": [
    "The `tagger` and `parser` are both present as expected, but so is the `ner` component which has its own `tok2vec` layer, separate from the `tok2vec` at the beginning of the `nlp.pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95f3edbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2Vec.v2',\n",
       " 'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "  'width': 96,\n",
       "  'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE'],\n",
       "  'rows': [5000, 1000, 2500, 2500],\n",
       "  'include_static_vectors': False},\n",
       " 'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "  'width': 96,\n",
       "  'depth': 4,\n",
       "  'window_size': 1,\n",
       "  'maxout_pieces': 3}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tok2vec = nlp.get_pipe_config(\"ner\")[\"model\"][\"tok2vec\"]\n",
    "ner_tok2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc0a5c4",
   "metadata": {},
   "source": [
    "The `tagger` and `parser` components both *listen to* or *share* the the tensors produced via the `tok2vec` component in the `nlp.pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf8f9cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2VecListener.v1',\n",
       " 'width': '${components.tok2vec.model.encode:width}',\n",
       " 'upstream': 'tok2vec'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_tok2vec = nlp.get_pipe_config(\"tagger\")[\"model\"][\"tok2vec\"]\n",
    "tagger_tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbea4dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2VecListener.v1',\n",
       " 'width': '${components.tok2vec.model.encode:width}',\n",
       " 'upstream': 'tok2vec'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser_tok2vec = nlp.get_pipe_config(\"parser\")[\"model\"][\"tok2vec\"]\n",
    "parser_tok2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd42bbaa",
   "metadata": {},
   "source": [
    "Listening to/sharing an upstream component has some pros and cons including speed and flexibility (docs; stack overflow answer). Sometimes sharing a component can help boost later components metrics, and other times it's easier to have something more independent.\n",
    "\n",
    "For example, suppose we wanted to fine-tune the weights in a `senter` component."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f053717",
   "metadata": {},
   "source": [
    "# TODO -- Add link to `senter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64f07172",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.enable_pipe(\"senter\")\n",
    "senter_config = nlp.get_pipe_config(\"senter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09d92288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factory': 'senter',\n",
       " 'model': {'@architectures': 'spacy.Tagger.v2',\n",
       "  'nO': None,\n",
       "  'normalize': False,\n",
       "  'tok2vec': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "   'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "    'width': 16,\n",
       "    'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY'],\n",
       "    'rows': [1000, 500, 500, 500, 50],\n",
       "    'include_static_vectors': False},\n",
       "   'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "    'width': 16,\n",
       "    'depth': 2,\n",
       "    'window_size': 1,\n",
       "    'maxout_pieces': 2}}},\n",
       " 'overwrite': False,\n",
       " 'scorer': {'@scorers': 'spacy.senter_scorer.v1'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senter_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e7d7a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factory': 'senter',\n",
       " 'model': {'@architectures': 'spacy.Tagger.v2',\n",
       "  'nO': None,\n",
       "  'normalize': False,\n",
       "  'tok2vec': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "   'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "    'width': 16,\n",
       "    'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY'],\n",
       "    'rows': [1000, 500, 500, 500, 50],\n",
       "    'include_static_vectors': False},\n",
       "   'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "    'width': 16,\n",
       "    'depth': 2,\n",
       "    'window_size': 1,\n",
       "    'maxout_pieces': 2}}},\n",
       " 'overwrite': False,\n",
       " 'scorer': {'@scorers': 'spacy.senter_scorer.v1'}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe_config(\"senter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20e5ac88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factory': 'tok2vec',\n",
       " 'model': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "  'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "   'width': '${components.tok2vec.model.encode:width}',\n",
       "   'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY', 'IS_SPACE'],\n",
       "   'rows': [5000, 1000, 2500, 2500, 50, 50],\n",
       "   'include_static_vectors': False},\n",
       "  'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "   'width': 96,\n",
       "   'depth': 4,\n",
       "   'window_size': 1,\n",
       "   'maxout_pieces': 3}}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe_config(\"tok2vec\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8fbb568",
   "metadata": {},
   "source": [
    "# construct a pipeline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "554b5796",
   "metadata": {},
   "source": [
    "# write the pipeline to disk"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a92bb74",
   "metadata": {},
   "source": [
    "# load the pipeline from disk"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b4c21b1",
   "metadata": {},
   "source": [
    "# view the pipeline's config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
