{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b843d3b",
   "metadata": {},
   "source": [
    "I've been working with [`spacy`](https://spacy.io/) more and more over the years, and I thought it'd be a good idea to write about the configuration system. There are mentions of it throughout the [docs](https://spacy.io/usage/training#config) and in some of the `spacy` 3.0 [videos](https://youtu.be/BWhh3r6W-qE), but I have yet to find a super detailed breakdown of what's going on (except maybe this [blog](https://explosion.ai/blog/spacy-v3-project-config-systems#spacy-config-system)). Hopefully this post will shed some light."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f809d2c",
   "metadata": {},
   "source": [
    "Let's start with a brief demo of `spacy`.\n",
    "\n",
    "> Install spacy and the `en_core_web_sm` model if you want to follow along:\n",
    "> ```shell\n",
    "$ pip install spacy\n",
    "$ python -m spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ef9fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, my name is Ian and this is my blog.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Hi, my name is Ian and this is my blog.\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf8b8a",
   "metadata": {},
   "source": [
    "Nothing fancy on the surface, but this [`doc`](https://spacy.io/api/doc) object that we've created is the product of sending our string of characters through a [pipeline of models](https://spacy.io/usage/processing-pipelines), or as `spacy` likes to call them, [components](https://spacy.io/usage/processing-pipelines#pipelines). We can view the pipeline components via the [`nlp.pipeline` property](https://spacy.io/api/language#attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b81a952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1ca902cbbf0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1ca90474230>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1ca901d1700>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x1ca90318990>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1ca90154c10>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1ca901d13f0>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45609a9b",
   "metadata": {},
   "source": [
    "And we can get more component information with [nlp.analyze_pipes](https://spacy.io/api/language#analyze_pipes) such as what each assigns, their requirements, their scoring metrics, whether they retokenize, and in what order the components perform their annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "520ed3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================= Pipeline Overview =============================\u001b[0m\n",
      "\n",
      "#   Component         Assigns               Requires   Scores             Retokenizes\n",
      "-   ---------------   -------------------   --------   ----------------   -----------\n",
      "0   tok2vec           doc.tensor                                          False      \n",
      "                                                                                     \n",
      "1   tagger            token.tag                        tag_acc            False      \n",
      "                                                                                     \n",
      "2   parser            token.dep                        dep_uas            False      \n",
      "                      token.head                       dep_las                       \n",
      "                      token.is_sent_start              dep_las_per_type              \n",
      "                      doc.sents                        sents_p                       \n",
      "                                                       sents_r                       \n",
      "                                                       sents_f                       \n",
      "                                                                                     \n",
      "3   attribute_ruler                                                       False      \n",
      "                                                                                     \n",
      "4   lemmatizer        token.lemma                      lemma_acc          False      \n",
      "                                                                                     \n",
      "5   ner               doc.ents                         ents_f             False      \n",
      "                      token.ent_iob                    ents_p                        \n",
      "                      token.ent_type                   ents_r                        \n",
      "                                                       ents_per_type                 \n",
      "\n",
      "\u001b[38;5;2mâœ” No problems found.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "nlp.analyze_pipes(pretty=True);  # note the semicolon (;) to reduce output after the table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a916404e",
   "metadata": {},
   "source": [
    "Notice the first component, `tok2vec`. This [component](https://spacy.io/api/tok2vec) is responsible for mapping tokens to vectors, i.e., creating an [embedding layer](https://spacy.io/usage/embeddings-transformers), and making them available for later components to use via the `doc.tensor` attribute.\n",
    "> Note, this is not the same as a [`tokenizer`](https://spacy.io/api/tokenizer).\n",
    "\n",
    "In the `en_core_web_sm` pipeline, we can see that the [`tagger`](https://spacy.io/api/tagger) and [`parser`](https://spacy.io/api/dependencyparser) components both use the `tok2vec`'s output by accessing the `tok2vec.listening_components`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777ca140",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok2vec = nlp.get_pipe(\"tok2vec\")\n",
    "tok2vec.listening_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e072f9",
   "metadata": {},
   "source": [
    "On the flip side, we can see which components *use* a `tok2vec` model by checking their configuration via `nlp.get_pipe_config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2ddaa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factory': 'parser',\n",
       " 'learn_tokens': False,\n",
       " 'min_action_freq': 30,\n",
       " 'model': {'@architectures': 'spacy.TransitionBasedParser.v2',\n",
       "  'state_type': 'parser',\n",
       "  'extra_state_tokens': False,\n",
       "  'hidden_width': 64,\n",
       "  'maxout_pieces': 2,\n",
       "  'use_upper': True,\n",
       "  'nO': None,\n",
       "  'tok2vec': {'@architectures': 'spacy.Tok2VecListener.v1',\n",
       "   'width': '${components.tok2vec.model.encode:width}',\n",
       "   'upstream': 'tok2vec'}},\n",
       " 'moves': None,\n",
       " 'scorer': {'@scorers': 'spacy.parser_scorer.v1'},\n",
       " 'update_with_oracle_cut_size': 100}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe_config(\"parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e7e2d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'moves': None,\n",
       " 'update_with_oracle_cut_size': 100,\n",
       " 'multitasks': [],\n",
       " 'min_action_freq': 30,\n",
       " 'learn_tokens': False,\n",
       " 'beam_width': 1,\n",
       " 'beam_density': 0.0,\n",
       " 'beam_update_prob': 0.0,\n",
       " 'incorrect_spans_key': None}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be4aa359",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nlp.get_pipe(\"parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcdc9bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.model.Model at 0x1ca90495ec0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8df417e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<spacy.pipeline.tok2vec.Tok2VecListener at 0x1ca90498550>,\n",
       " <thinc.model.Model at 0x1ca904895c0>,\n",
       " <thinc.model.Model at 0x1ca90495440>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.model.layers[0].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c758a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = nlp.get_pipe(\"tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2edd4677",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tagger' object has no attribute 'tok2vec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtok2vec\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tagger' object has no attribute 'tok2vec'"
     ]
    }
   ],
   "source": [
    "tagger.tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81ffafaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tagger': [<spacy.pipeline.tok2vec.Tok2VecListener at 0x1ca904982d0>],\n",
       " 'parser': [<spacy.pipeline.tok2vec.Tok2VecListener at 0x1ca90498550>]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok2vec.listener_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39aad9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<spacy.pipeline.tok2vec.Tok2VecListener at 0x1ca904982d0>,\n",
       " <thinc.model.Model at 0x1ca9048b8c0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7a368e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factory': 'ner',\n",
       " 'incorrect_spans_key': None,\n",
       " 'model': {'@architectures': 'spacy.TransitionBasedParser.v2',\n",
       "  'state_type': 'ner',\n",
       "  'extra_state_tokens': False,\n",
       "  'hidden_width': 64,\n",
       "  'maxout_pieces': 2,\n",
       "  'use_upper': True,\n",
       "  'nO': None,\n",
       "  'tok2vec': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "   'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "    'width': 96,\n",
       "    'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE'],\n",
       "    'rows': [5000, 1000, 2500, 2500],\n",
       "    'include_static_vectors': False},\n",
       "   'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "    'width': 96,\n",
       "    'depth': 4,\n",
       "    'window_size': 1,\n",
       "    'maxout_pieces': 3}}},\n",
       " 'moves': None,\n",
       " 'scorer': {'@scorers': 'spacy.ner_scorer.v1'},\n",
       " 'update_with_oracle_cut_size': 100}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe_config(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fcb64c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factory': 'tagger',\n",
       " 'label_smoothing': 0.0,\n",
       " 'model': {'@architectures': 'spacy.Tagger.v2',\n",
       "  'nO': None,\n",
       "  'normalize': False,\n",
       "  'tok2vec': {'@architectures': 'spacy.Tok2VecListener.v1',\n",
       "   'width': '${components.tok2vec.model.encode:width}',\n",
       "   'upstream': 'tok2vec'}},\n",
       " 'neg_prefix': '!',\n",
       " 'overwrite': False,\n",
       " 'scorer': {'@scorers': 'spacy.tagger_scorer.v1'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe_config(\"tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "247f24f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', False),\n",
       " ('tagger', False),\n",
       " ('parser', True),\n",
       " ('attribute_ruler', False),\n",
       " ('lemmatizer', False),\n",
       " ('ner', True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, hasattr(component, \"tok2vec\")) for name, component in nlp.pipeline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f026cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12cc9282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(ner, \"tok2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fad2103d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factory': 'ner',\n",
       " 'incorrect_spans_key': None,\n",
       " 'model': {'@architectures': 'spacy.TransitionBasedParser.v2',\n",
       "  'state_type': 'ner',\n",
       "  'extra_state_tokens': False,\n",
       "  'hidden_width': 64,\n",
       "  'maxout_pieces': 2,\n",
       "  'use_upper': True,\n",
       "  'nO': None,\n",
       "  'tok2vec': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "   'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "    'width': 96,\n",
       "    'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE'],\n",
       "    'rows': [5000, 1000, 2500, 2500],\n",
       "    'include_static_vectors': False},\n",
       "   'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "    'width': 96,\n",
       "    'depth': 4,\n",
       "    'window_size': 1,\n",
       "    'maxout_pieces': 3}}},\n",
       " 'moves': None,\n",
       " 'scorer': {'@scorers': 'spacy.ner_scorer.v1'},\n",
       " 'update_with_oracle_cut_size': 100}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe_config(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dfa753c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<spacy.pipeline.tok2vec.Tok2Vec object at 0x000001CA902CBBF0>\n",
      "<spacy.pipeline.tagger.Tagger object at 0x000001CA90474230>\n",
      "<spacy.pipeline.dep_parser.DependencyParser object at 0x000001CA901D1700>\n",
      "<spacy.pipeline.attributeruler.AttributeRuler object at 0x000001CA90318990>\n",
      "<spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x000001CA90154C10>\n",
      "<spacy.pipeline.ner.EntityRecognizer object at 0x000001CA901D13F0>\n"
     ]
    }
   ],
   "source": [
    "for pipe in nlp.pipe_names:\n",
    "    print(nlp.get_pipe(pipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f177ed",
   "metadata": {},
   "source": [
    "You can see that the `ner` component has a `tok2vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79263659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.tokenizer.Tokenizer at 0x1cc3d03f9a0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9a2ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok2vec = nlp.get_pipe(\"tok2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02cf9abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1cc3df79970>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1cc3df7aed0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1cc3d103bc0>),\n",
       " ('senter', <spacy.pipeline.senter.SentenceRecognizer at 0x1cc3df79cd0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x1cc3d417450>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1cc3df4bf50>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1cc3d103b50>)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f896ae69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tok2vec.find_listeners(c) for c in nlp.components]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77a51823",
   "metadata": {},
   "source": [
    "# highlight the arguments of a couple components: tok2vec + one other"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8fbb568",
   "metadata": {},
   "source": [
    "# construct a pipeline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "554b5796",
   "metadata": {},
   "source": [
    "# write the pipeline to disk"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a92bb74",
   "metadata": {},
   "source": [
    "# load the pipeline from disk"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b4c21b1",
   "metadata": {},
   "source": [
    "# view the pipeline's config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
