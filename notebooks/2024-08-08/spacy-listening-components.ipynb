{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b843d3b",
   "metadata": {},
   "source": [
    "I've been working with [`spacy`](https://spacy.io/) more and more over the years, and I thought it'd be a good idea to write about pieces of the configuration system. There are mentions of it throughout the [docs](https://spacy.io/usage/training#config) and in some of the `spacy` 3.0 [videos](https://youtu.be/BWhh3r6W-qE), but I have yet to find a super detailed breakdown of what's going on—the closest being this [blog](https://explosion.ai/blog/spacy-v3-project-config-systems#spacy-config-system). This post will hopefully shed some light on the components that [*share* or *listen to*](https://spacy.io/usage/embeddings-transformers#embedding-layers) previous components in the pipeline.\n",
    "\n",
    "Let's start with a brief demo of `spacy`.\n",
    "\n",
    "> Install `spacy` and the `en_core_web_sm` model if you want to follow along:\n",
    "> ```shell\n",
    "$ pip install spacy\n",
    "$ python -m spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d6af1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, my name is Ian and this is my blog.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Hi, my name is Ian and this is my blog.\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af523ab",
   "metadata": {},
   "source": [
    "Nothing fancy on the surface, but this [`doc`](https://spacy.io/api/doc) object that we've created is the product of sending our string of characters through a [pipeline of models](https://spacy.io/usage/processing-pipelines), or as `spacy` likes to call them, [components](https://spacy.io/usage/processing-pipelines#pipelines). We can view the pipeline components via the [`nlp.pipeline` property](https://spacy.io/api/language#attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0310baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1ed788cbc50>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1ed78a741d0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1ed787cd620>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x1ed7890f5d0>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1ed78919050>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1ed787cd310>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b5631d",
   "metadata": {},
   "source": [
    "And we can get more component information with [`nlp.analyze_pipes`](https://spacy.io/api/language#analyze_pipes) such as what each assigns, their requirements, their scoring metrics, whether they retokenize, and in what order the components perform their annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f5624f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================= Pipeline Overview =============================\u001b[0m\n",
      "\n",
      "#   Component         Assigns               Requires   Scores             Retokenizes\n",
      "-   ---------------   -------------------   --------   ----------------   -----------\n",
      "0   tok2vec           doc.tensor                                          False      \n",
      "                                                                                     \n",
      "1   tagger            token.tag                        tag_acc            False      \n",
      "                                                                                     \n",
      "2   parser            token.dep                        dep_uas            False      \n",
      "                      token.head                       dep_las                       \n",
      "                      token.is_sent_start              dep_las_per_type              \n",
      "                      doc.sents                        sents_p                       \n",
      "                                                       sents_r                       \n",
      "                                                       sents_f                       \n",
      "                                                                                     \n",
      "3   attribute_ruler                                                       False      \n",
      "                                                                                     \n",
      "4   lemmatizer        token.lemma                      lemma_acc          False      \n",
      "                                                                                     \n",
      "5   ner               doc.ents                         ents_f             False      \n",
      "                      token.ent_iob                    ents_p                        \n",
      "                      token.ent_type                   ents_r                        \n",
      "                                                       ents_per_type                 \n",
      "\n",
      "\u001b[38;5;2m✔ No problems found.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# note the semicolon (;) to reduce output after the table.\n",
    "nlp.analyze_pipes(pretty=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddcb6c4",
   "metadata": {},
   "source": [
    "Notice the first component, `tok2vec`. This [component](https://spacy.io/api/tok2vec) is responsible for mapping tokens to vectors, i.e., creating an [embedding layer](https://spacy.io/usage/embeddings-transformers), and making them available for later components to use via the `doc.tensor` attribute.\n",
    "> Note, this is not the same as a [`tokenizer`](https://spacy.io/api/tokenizer).\n",
    "\n",
    "In the [`en_core_web_sm`](https://spacy.io/models/en#en_core_web_sm) pipeline, we can see that the [`tagger`](https://spacy.io/api/tagger) and [`parser`](https://spacy.io/api/dependencyparser) components both use the `tok2vec`'s output by accessing the `tok2vec.listening_components`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad3c341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok2vec = nlp.get_pipe(\"tok2vec\")\n",
    "tok2vec.listening_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889dafcd",
   "metadata": {},
   "source": [
    "On the flip side, we can see which components *use* a `tok2vec` model by checking their configurations via `nlp.get_pipe_config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f072c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    name\n",
    "    for name in nlp.pipe_names\n",
    "    if (model := nlp.get_pipe_config(name).get(\"model\")) is not None\n",
    "    and model.get(\"tok2vec\") is not None\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be687ffb",
   "metadata": {},
   "source": [
    "The `tagger` and `parser` are both present as expected, but so is the `ner` component which has its own `tok2vec` layer, separate from the `tok2vec` at the beginning of the `nlp.pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be187867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2Vec.v2',\n",
       " 'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "  'width': 96,\n",
       "  'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE'],\n",
       "  'rows': [5000, 1000, 2500, 2500],\n",
       "  'include_static_vectors': False},\n",
       " 'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "  'width': 96,\n",
       "  'depth': 4,\n",
       "  'window_size': 1,\n",
       "  'maxout_pieces': 3}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tok2vec = nlp.get_pipe_config(\"ner\")[\"model\"][\"tok2vec\"]\n",
    "ner_tok2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0df555d",
   "metadata": {},
   "source": [
    "This is an example of an *independent* component—it can stand alone without the other other components.\n",
    "\n",
    "The `tagger` and `parser` components both *listen to* or *share* the `tok2vec` component's output in the `nlp.pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59624d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2VecListener.v1',\n",
       " 'width': '${components.tok2vec.model.encode:width}',\n",
       " 'upstream': 'tok2vec'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_tok2vec = nlp.get_pipe_config(\"tagger\")[\"model\"][\"tok2vec\"]\n",
    "tagger_tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa14d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2VecListener.v1',\n",
       " 'width': '${components.tok2vec.model.encode:width}',\n",
       " 'upstream': 'tok2vec'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser_tok2vec = nlp.get_pipe_config(\"parser\")[\"model\"][\"tok2vec\"]\n",
    "parser_tok2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b1f4e",
   "metadata": {},
   "source": [
    "Listening to/sharing an upstream component has some pros and cons including speed and flexibility (see my [stack overflow answer](https://stackoverflow.com/a/76774652/6509519) for an experiment). Sometimes sharing a component can help boost later components metrics, and other times it's easier to have something more independent.\n",
    "\n",
    "When it comes to training components that listen to the same `tok2vec` layer, we have options.\n",
    "- We could add a component with its own `tok2vec` similar to the `ner` component.\n",
    "- We could add a component and have it listen to the existing `tok2vec` layer.\n",
    "- We could add both a component and have it listen to a *new* `tok2vec` component, separate from the existing one (rarely would you want to do this).\n",
    "\n",
    "Here is an example of the first option—we'll enable the [`senter`](https://spacy.io/api/sentencerecognizer) model (which is pre-trained so we won't need to actually train it), and view its `tok2vec` setup.\n",
    "\n",
    "> Note, you could do this with a custom component as well assuming it's registered or in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6301d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2Vec.v2',\n",
       " 'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "  'width': 16,\n",
       "  'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY'],\n",
       "  'rows': [1000, 500, 500, 500, 50],\n",
       "  'include_static_vectors': False},\n",
       " 'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "  'width': 16,\n",
       "  'depth': 2,\n",
       "  'window_size': 1,\n",
       "  'maxout_pieces': 2}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.enable_pipe(\"senter\")\n",
    "senter_tok2vec = nlp.get_pipe_config(\"senter\")[\"model\"][\"tok2vec\"]\n",
    "\n",
    "senter_tok2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18722ee3",
   "metadata": {},
   "source": [
    "Pretty easy to do. If we wanted something more like the second option, we'd need to update the [`nlp.config`](https://spacy.io/api/language#config) telling `spacy` that we want the `senter` to listen to the existing `tok2vec` component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "def3d0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path extracted from ``parser_tok2vec`` -> ${components.tok2vec.model.encode:width}\n",
    "width = tok2vec.model.get_ref(\"encode\").get_dim(\"nO\")\n",
    "\n",
    "senter_config = {\n",
    "    \"model\": {\n",
    "        \"tok2vec\": {\n",
    "            \"@architectures\": \"spacy.Tok2VecListener.v1\",\n",
    "            \"width\": width,\n",
    "            \"upstream\": \"tok2vec\",\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "# Before adding ``senter`` with listener.\n",
    "tok2vec.listening_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eee94ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'senter']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing existing ``senter`` model without listener.\n",
    "nlp.remove_pipe(\"senter\")\n",
    "\n",
    "# Adding new ``senter`` model with listener.\n",
    "# nlp.add_pipe(\"senter\", after=\"parser\", config=senter_config)\n",
    "nlp.add_pipe(\"senter\", after=\"parser\", config=senter_config)\n",
    "\n",
    "# After adding ``senter`` with listener.\n",
    "tok2vec.listening_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e489465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2VecListener.v1',\n",
       " 'width': 96,\n",
       " 'upstream': 'tok2vec'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe_config(\"senter\")[\"model\"][\"tok2vec\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdb90e9",
   "metadata": {},
   "source": [
    "The `senter` component has its own `tok2vec` layer just like the `ner` component. If we wanted to have it listen to the same `tok2vec` as the `tagger` and `parser` we could add a listner to the `tok2vec` using the `tok2vec.add_listener` method. This requires us to create a `Tok2VecListener` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e420dd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.pipeline.tok2vec import Tok2VecListener\n",
    "\n",
    "# Taking the width from the current `tok2vec` config\n",
    "width = nlp.get_pipe_config(\"tok2vec\")[\"model\"][\"encode\"][\"width\"]\n",
    "tok2vec_listener = Tok2VecListener(upstream_name=\"*\", width=width)\n",
    "\n",
    "# Current listeners\n",
    "tok2vec.listening_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a7472d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'senter']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok2vec.add_listener(listener=tok2vec_listener, component_name=\"senter\")\n",
    "\n",
    "# New listeners\n",
    "tok2vec.listening_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9ac5124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2VecListener.v1',\n",
       " 'width': '${components.tok2vec.model.encode:width}',\n",
       " 'upstream': 'tok2vec'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "49dd29a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tok2Vec.find_listeners() missing 1 required positional argument: 'component'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtok2vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_listeners\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Tok2Vec.find_listeners() missing 1 required positional argument: 'component'"
     ]
    }
   ],
   "source": [
    "tok2vec.find_listeners()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "683913b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp._link_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a22423e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factory': 'senter',\n",
       " 'model': {'@architectures': 'spacy.Tagger.v2',\n",
       "  'nO': None,\n",
       "  'normalize': False,\n",
       "  'tok2vec': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "   'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "    'width': 16,\n",
       "    'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY'],\n",
       "    'rows': [1000, 500, 500, 500, 50],\n",
       "    'include_static_vectors': False},\n",
       "   'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "    'width': 16,\n",
       "    'depth': 2,\n",
       "    'window_size': 1,\n",
       "    'maxout_pieces': 2}}},\n",
       " 'overwrite': False,\n",
       " 'scorer': {'@scorers': 'spacy.senter_scorer.v1'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.config[\"components\"][\"senter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1ab309e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2Vec.v2',\n",
       " 'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "  'width': 16,\n",
       "  'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY'],\n",
       "  'rows': [1000, 500, 500, 500, 50],\n",
       "  'include_static_vectors': False},\n",
       " 'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "  'width': 16,\n",
       "  'depth': 2,\n",
       "  'window_size': 1,\n",
       "  'maxout_pieces': 2}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe_config(\"senter\")[\"model\"][\"tok2vec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5e1d2f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tok2Vec.v2',\n",
       " 'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "  'width': 16,\n",
       "  'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY'],\n",
       "  'rows': [1000, 500, 500, 500, 50],\n",
       "  'include_static_vectors': False},\n",
       " 'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "  'width': 16,\n",
       "  'depth': 2,\n",
       "  'window_size': 1,\n",
       "  'maxout_pieces': 2}}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe_config(\"senter\")[\"model\"][\"tok2vec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc29f9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@architectures': 'spacy.Tagger.v2',\n",
       " 'nO': None,\n",
       " 'normalize': False,\n",
       " 'tok2vec': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "  'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "   'width': 16,\n",
       "   'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY'],\n",
       "   'rows': [1000, 500, 500, 500, 50],\n",
       "   'include_static_vectors': False},\n",
       "  'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "   'width': 16,\n",
       "   'depth': 2,\n",
       "   'window_size': 1,\n",
       "   'maxout_pieces': 2}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe_config(\"senter\")[\"model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52991d",
   "metadata": {},
   "source": [
    "> Note that running the text through the pipeline *before* modifying the `senter`'s `tok2vec` layer would also produce a `doc` with `sents`, but the results may differ as the `senter` component has not been trained with this `tok2vec` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c69265f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "senter = nlp.get_pipe(\"senter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "263618aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.model.Model at 0x2595ede4a40>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
